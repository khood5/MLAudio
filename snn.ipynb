{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from audioDataLoader import audioDataloader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sys\n",
    "import neuro\n",
    "from py_apps import utils\n",
    "from py_apps.utils.common_utils import read_network\n",
    "from py_apps.utils.common_utils import load_json_arg\n",
    "from py_apps.utils.neuro_help import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Classification Application Driver\")\n",
    "parser.add_argument(\"--activity\", \"-a\", required=True, type=str, choices=[\"train\", \"test\"], help=\"activity to perform\")\n",
    "args = parser.parse_args([\"--activity\",\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Classification Application Driver\")\n",
    "parser.add_argument(\"--activity\", \"-a\", required=True, type=str, choices=[\"train\", \"test\"], help=\"activity to perform\")\n",
    "parser.add_argument(\"--network_filename\", default=None, type=str, help=\"location to store the best network file produced if training or network to load if testing\")\n",
    "parser.add_argument(\"--sim_time\", default=50, type=float, help=\"the simulation timefor each data instance\")\n",
    "parser.add_argument(\"--eons_params\", default=\"config/eons.json\", type=str, help=\"JSON file with EONS parameters\")\n",
    "parser.add_argument(\"--extra_eons_params\", default=\"{}\", type=str ,help=\"JSON file or JSON string updating EONS parameters from configuration file\")\n",
    "parser.add_argument(\"--epochs\", default=50, type=int, help=\"epochs for eons\")\n",
    "parser.add_argument(\"--max_fitness\", default=1e+06, type=float, help=\"max fitness for eons\")\n",
    "parser.add_argument(\"--processes\", default=1, type=int, help=\"processes for EONS\")\n",
    "parser.add_argument(\"--test_seed\", default=1234, type=int, help=\"testing seed\")\n",
    "\n",
    "# Classification params\n",
    "add_class_arguments(parser)\n",
    "\n",
    "# Proc params \n",
    "add_proc_arguments(parser)\n",
    "\n",
    "    # Encoder information\n",
    "add_coder_arguments(parser)\n",
    "\n",
    "# Printing params\n",
    "add_printing_arguments(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = \"\"\"\n",
    "\t-a train \\\n",
    "\t--proc_params ./config/risp.json\\\n",
    "\t--eons_params ./config/eons_SPG.json\\\n",
    "\t--timeseries true \\\n",
    "\t--app_type load \\\n",
    "\t--data_np /data2/khood/GitHub/MLAudio/neuroTrain.npy \\\n",
    "\t--labels_np /data2/khood/GitHub/MLAudio/neuroTrain_labels.npy \\\n",
    "\t--encoder {\"spikes\":{\"min\":0,\"max\":1}} \\\n",
    "\t--processes 1 \\\n",
    "\t--sim_time 201 \\\n",
    "\t--epochs 3 \\\n",
    "\t--network_filename test_eons.json\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(params.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Read in proc params as necessary\n",
    "proc_params = load_json_arg(args.proc_params)\n",
    "extra_proc_params = load_json_arg(args.extra_proc_params)\n",
    "for k in extra_proc_params.keys():\n",
    "    proc_params[k] = extra_proc_params[k]\n",
    "\n",
    "# Read in EONS params\n",
    "eons_params = load_json_arg(args.eons_params)\n",
    "\n",
    "#Read in extra EONS params\n",
    "extra_eons_params = load_json_arg(args.extra_eons_params)\n",
    "\n",
    "for k in extra_eons_params.keys():\n",
    "    eons_params[k] = extra_eons_params[k]\n",
    "#print(eons_params)\n",
    "\n",
    "proc_instantiation = get_proc_instantiation(args.proc_name)\n",
    "\n",
    "# Instantiate data\n",
    "X, y = setup_data(args)\n",
    "\n",
    "config = setup_class_config(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_apps.utils.classify_app import ClassifyApp\n",
    "import networkx as nx\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyAudioApp(ClassifyApp):\n",
    "    def __init__(self, config, X, y):\n",
    "        super().__init__(config, X, y) \n",
    "    \n",
    "    def fitness(self, net: neuro.Network, proc, id_for_printing=-1):\n",
    "        \n",
    "        net.prune()\n",
    "        missing_path_penalty = self._count_missing_input_output_paths(net)\n",
    "        if missing_path_penalty != 0:\n",
    "            return missing_path_penalty\n",
    "        y_predict = self.predict(proc, net, self.X_train)\n",
    "        if (self.fitness_type == \"accuracy\"):\n",
    "            ret = accuracy_score(self.y_train, y_predict) \n",
    "        elif (self.fitness_type == \"f1\"):\n",
    "            ret = f1_score(self.y_train, y_predict, average=\"weighted\")\n",
    "        return ret\n",
    "    \n",
    "    def _count_missing_input_output_paths(self, net: neuro.Network):\n",
    "            # Modified BFS to only visit a node when ALL of its incoming nodes have already been visited\n",
    "            snnModel_raw = json.loads(json.dumps(net.as_json().to_python()))\n",
    "            G = nx.Graph()\n",
    "\n",
    "            for n in snnModel_raw['Nodes']:\n",
    "                G.add_node(n['id'])\n",
    "\n",
    "            for e in snnModel_raw['Edges']:\n",
    "                G.add_edge(e['from'], e['to'], weight=round(e['values'][0],3))\n",
    "\n",
    "            inputNodes = snnModel_raw[\"Inputs\"]\n",
    "            outputNodes = snnModel_raw[\"Outputs\"]\n",
    "\n",
    "            number_of_missing_paths = 0\n",
    "            for subStation in inputNodes:\n",
    "                for out in outputNodes:\n",
    "                    if not nx.has_path(G,subStation, out):\n",
    "                        number_of_missing_paths = number_of_missing_paths - 10\n",
    "            return number_of_missing_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"spikes\":{\"min\":0,\"max\":1}}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if (args.activity == \"train\"):\n",
    "        app = ClassifyAudioApp(config, X, y)\n",
    "\n",
    "        train_params = {}\n",
    "        train_params[\"eons_params\"] = eons_params\n",
    "        train_params[\"num_epochs\"] = args.epochs\n",
    "        train_params[\"num_processes\"] = args.processes\n",
    "        train_params[\"fitness\"] = args.fitness\n",
    "        train_start = time.time()\n",
    "        app.train(train_params, proc_instantiation, proc_params)\n",
    "        train_end = time.time()\n",
    "        elapsed = train_end-train_start\n",
    "        net = app.overall_best_net\n",
    "        net.prune()\n",
    "        print(\"Network size:\", net.num_nodes(), net.num_edges())\n",
    "        print(\"Training Time:\", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compairing running configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate mlaudio\n",
    "python snn.py\\\n",
    "\t-a train \\\n",
    "\t--proc_params ./config/risp.json\\\n",
    "\t--eons_params ./config/eons.json\\\n",
    "\t--timeseries true \\\n",
    "\t--app_type load \\\n",
    "\t--data_np /data2/khood/GitHub/MLAudio/numpyData/valid.npy \\\n",
    "\t--labels_np /data2/khood/GitHub/MLAudio/numpyData/valid_labels.npy \\\n",
    "\t--encoder config/encoder.json \\\n",
    "\t--processes <strong><ins>4</ins></strong> \\\n",
    "\t--sim_time 7201 \\\n",
    "\t--epochs 3 \\\n",
    "\t--network_filename test_eons.json\\\n",
    "    --split 0\n",
    "</pre>\n",
    "\n",
    "#### result\n",
    "<pre>\n",
    "Reading classification params\n",
    "Reading proc params\n",
    "Reading encoder information\n",
    "Reading printing params\n",
    "Reading in proc params as necessary\n",
    "Reading in EONS params\n",
    "Reading in extra EONS params\n",
    "Instantiate data\n",
    "Starting training\n",
    "Epoch:   0     Time: 2410.7     Best: -143920    Num_Synapses: 2775\n",
    "Epoch:   1     Time: 2722.6     Best: -143660    Num_Synapses: 2775\n",
    "Epoch:   2     Time: 2775.8     Best: -143640    Num_Synapses: 2774\n",
    "Network size: 7203 2711\n",
    "Training Time: 7911.819289684296\n",
    "</pre>\n",
    "\n",
    "<pre>\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate mlaudio\n",
    "python snn.py\\\n",
    "\t-a train \\\n",
    "\t--proc_params ./config/risp.json\\\n",
    "\t--eons_params ./config/eons.json\\\n",
    "\t--timeseries true \\\n",
    "\t--app_type load \\\n",
    "\t--data_np /data2/khood/GitHub/MLAudio/numpyData/valid.npy \\\n",
    "\t--labels_np /data2/khood/GitHub/MLAudio/numpyData/valid_labels.npy \\\n",
    "\t--encoder config/encoder.json \\\n",
    "\t--processes <strong><ins>16</strong></ins> \\\n",
    "\t--sim_time 7201 \\\n",
    "\t--epochs 3 \\\n",
    "\t--network_filename test_eons.json\\\n",
    "    --split 0\n",
    "</pre>\n",
    "\n",
    "#### result\n",
    "\n",
    "<pre>\n",
    "Reading classification params\n",
    "Reading proc params\n",
    "Reading encoder information\n",
    "Reading printing params\n",
    "Reading in proc params as necessary\n",
    "Reading in EONS params\n",
    "Reading in extra EONS params\n",
    "Instantiate data\n",
    "Starting training\n",
    "Epoch:   0     Time: 4390.3     Best: -143300    Num_Synapses: 2775\n",
    "Epoch:   1     Time: 5330.0     Best: -143300    Num_Synapses: 2775\n",
    "Epoch:   2     Time: 5183.9     Best: -143300    Num_Synapses: 2775\n",
    "Network size: 7203 2708\n",
    "Training Time: 14907.133779287338\n",
    "</pre>\n",
    "\n",
    "<pre>\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate mlaudio\n",
    "python snn.py\\\n",
    "\t-a train \\\n",
    "\t--proc_params ./config/risp.json\\\n",
    "\t--eons_params ./config/eons.json\\\n",
    "\t--timeseries true \\\n",
    "\t--app_type load \\\n",
    "\t--data_np /data2/khood/GitHub/MLAudio/numpyData/valid.npy \\\n",
    "\t--labels_np /data2/khood/GitHub/MLAudio/numpyData/valid_labels.npy \\\n",
    "\t--encoder config/encoder.json \\\n",
    "\t--processes <strong><ins>1</strong></ins> \\\n",
    "\t--sim_time 7201 \\\n",
    "\t--epochs 3 \\\n",
    "\t--network_filename test_eons.json\\\n",
    "    --split 0\n",
    "</pre>\n",
    "\n",
    "#### result\n",
    "\n",
    "<pre>\n",
    "Reading classification params\n",
    "Reading proc params\n",
    "Reading encoder information\n",
    "Reading printing params\n",
    "Reading in proc params as necessary\n",
    "Reading in EONS params\n",
    "Reading in extra EONS params\n",
    "Instantiate data\n",
    "Starting training\n",
    "Epoch:   0     Time:  826.8     Best: -143730    Num_Synapses: 2775\n",
    "Epoch:   1     Time:  865.8     Best: -143730    Num_Synapses: 2775\n",
    "Epoch:   2     Time:  861.8     Best: -143730    Num_Synapses: 2775\n",
    "Network size: 7203 2725\n",
    "Training Time: 2557.108283996582\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
