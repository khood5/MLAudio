{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "296184ea-9259-4dbe-a1e0-2e54595131b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eons\n",
    "import neuro\n",
    "import risp\n",
    "import speech2spikes\n",
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "import random\n",
    "\n",
    "PATH_GUNSHOT_SOUNDS = '/home/joao/dev/MLAudio/shotspotter/data/gunshots'\n",
    "PATH_NOGUNSHOT_SOUNDS = '/home/joao/dev/MLAudio/shotspotter/data/genBackgrounds'\n",
    "\n",
    "# Look into possible enabling cumsum (see github)\n",
    "s2s = speech2spikes.S2S()\n",
    "\n",
    "# workaround to configure to 12khz sample rate (s2s.configure() didnt work)\n",
    "s2s._default_spec_kwargs = {\n",
    "    \"sample_rate\": 12000,\n",
    "    \"n_mels\": 20,\n",
    "    \"n_fft\": 512,\n",
    "    \"f_min\": 20,\n",
    "    \"f_max\": 4000,\n",
    "    \"hop_length\": 80,\n",
    "}\n",
    "s2s.transform = torchaudio.transforms.MelSpectrogram(**s2s._default_spec_kwargs)\n",
    "\n",
    "# Some constants\n",
    "NUM_INPUT_NEURONS = 80 # see paper\n",
    "NUM_OUTPUT_NEURONS = 2\n",
    "NUM_SYNAPSES = 500\n",
    "NUM_HIDDEN_NEURONS = 100\n",
    "POP_SIZE = 50\n",
    "\n",
    "MOA = neuro.MOA()\n",
    "MOA.seed(23456789, '')\n",
    "\n",
    "DATASET_CAP = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f516ca5e-af5f-4ec6-8e4f-ec9cdfc2ba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 50 gunshot audio files\n",
      "We have 50 background only audio files\n"
     ]
    }
   ],
   "source": [
    "gunshot_file_paths = [PATH_GUNSHOT_SOUNDS+'/'+fn for fn in os.listdir(PATH_GUNSHOT_SOUNDS)][:DATASET_CAP//2]\n",
    "print(f'We have {len(gunshot_file_paths)} gunshot audio files')\n",
    "nogunshot_file_paths = [PATH_NOGUNSHOT_SOUNDS+'/'+fn for fn in os.listdir(PATH_NOGUNSHOT_SOUNDS)][:DATASET_CAP//2]\n",
    "print(f'We have {len(nogunshot_file_paths)} background only audio files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b339a9da-0026-47e8-b723-043aec39e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to convert our sound file into spikes\n",
    "# WARNING: this is VERY bad, bc we save spikes that have values of 0, want to skip these (do later)\n",
    "def to_spikes(paths_list, labels):\n",
    "    data = []\n",
    "    for p in paths_list:\n",
    "        samples, rate = torchaudio.load(p)\n",
    "        data.append(samples)\n",
    "\n",
    "    trains, targets = s2s([(data[i], torch.tensor(labels[i])) for i in range(len(paths_list))])\n",
    "    #print(trains.shape)\n",
    "\n",
    "    # LOOK INTO EXACTLY WHAT CUMSUM IS DOING so we can figure out conversion to spikes\n",
    "    # with cumsum=False (default) looks like it makes sense\n",
    "    # I think we dont want cumsum (not entirely sure of what its doing)\n",
    "\n",
    "    #print(trains[0][0])\n",
    "\n",
    "    all_spikes = []\n",
    "\n",
    "    for train in trains:\n",
    "        spikes = []\n",
    "        spike_id_count = 0\n",
    "        for i in range(2):\n",
    "            for channel in train[i]:\n",
    "                pos_channel, neg_channel = [], []\n",
    "                pos_id, neg_id = spike_id_count, spike_id_count+1\n",
    "                for t in range(len(channel)):\n",
    "                    if channel[t] == 1:\n",
    "                        pos_channel.append(neuro.Spike(pos_id, t, 1))\n",
    "                        neg_channel.append(neuro.Spike(neg_id, t, 0))\n",
    "                    elif channel[t] == -1:\n",
    "                        neg_channel.append(neuro.Spike(neg_id, t, 1))\n",
    "                        pos_channel.append(neuro.Spike(pos_id, t, 0))\n",
    "                    else:\n",
    "                        pos_channel.append(neuro.Spike(pos_id, t, 0))\n",
    "                        neg_channel.append(neuro.Spike(neg_id, t, 0))\n",
    "    \n",
    "                spikes.append(pos_channel.copy())\n",
    "                spikes.append(neg_channel.copy())\n",
    "\n",
    "                spike_id_count += 2\n",
    "\n",
    "        all_spikes.append(spikes.copy())\n",
    "\n",
    "    return all_spikes, targets\n",
    "\n",
    "\n",
    "# debug output of to_spikes\n",
    "def print_spikes(spks, channel_id):\n",
    "    # channel id from 0-79\n",
    "    for i in range(len(spks[1])):\n",
    "        print(f'{spks[channel_id][i].value:.0f}', end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13869364-aedd-4342-b4a3-7bd72f8afaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data \n",
    "p1 = [(i, 1) for i in gunshot_file_paths]\n",
    "p2 = [(i, 0) for i in nogunshot_file_paths]\n",
    "\n",
    "pairs = p1+p2 # path to sound - label tuples\n",
    "random.shuffle(pairs)\n",
    "\n",
    "spikes, labels = to_spikes([i[0] for i in pairs], [i[1] for i in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c86aadc5-f708-43f3-ac7c-d91855362f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure RISP and EONS\n",
    "risp_config = {\n",
    "  \"min_weight\": -1,\n",
    "  \"max_weight\": 1,\n",
    "  \"min_threshold\": -1,\n",
    "  \"max_threshold\": 1,\n",
    "  \"min_potential\": -1,\n",
    "  \"max_delay\": 10,\n",
    "  \"discrete\": False\n",
    "}\n",
    "\n",
    "eons_param = {\n",
    "    \"starting_nodes\": NUM_HIDDEN_NEURONS,\n",
    "    \"starting_edges\": NUM_SYNAPSES,\n",
    "    \"merge_rate\": 0,\n",
    "    \"population_size\": POP_SIZE,\n",
    "    \"multi_edges\": 0,\n",
    "    \"crossover_rate\": 0.9,\n",
    "    \"mutation_rate\": 0.9,\n",
    "    \"selection_type\": \"tournament\",\n",
    "    \"tournament_size_factor\": 0.1,\n",
    "    \"tournament_best_net_factor\": 0.9,\n",
    "    \"random_factor\": 0.10,\n",
    "    \"num_mutations\": 10,\n",
    "    \"node_mutations\": { \"Threshold\": 1.0 },\n",
    "    \"net_mutations\": { },\n",
    "    \"edge_mutations\": { \"Weight\": 0.65 , \"Delay\": 0.35,  },\n",
    "    \"num_best\" : 4,\n",
    "    \"add_node_rate\": 0.75,\n",
    "    \"delete_node_rate\": 0.25,\n",
    "    \"add_edge_rate\": 0.75,\n",
    "    \"delete_edge_rate\": 0.25,\n",
    "    \"node_params_rate\": 2.5,\n",
    "    \"edge_params_rate\": 2.5,\n",
    "    \"net_params_rate\" : 0\n",
    "}\n",
    "\n",
    "proc = risp.Processor(risp_config)\n",
    "eons_inst = eons.EONS(eons_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff60e6dc-094d-489d-812b-da9923d91f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up template network  (inputs and outputs) for eons\n",
    "template_net = neuro.Network()\n",
    "template_net.set_properties(proc.get_network_properties())\n",
    "\n",
    "for i in range(NUM_INPUT_NEURONS):\n",
    "    node = template_net.add_node(i)\n",
    "    node.set(\"Threshold\", 1)\n",
    "    template_net.add_input(i)\n",
    "\n",
    "for i in range(NUM_INPUT_NEURONS, NUM_INPUT_NEURONS+NUM_OUTPUT_NEURONS):\n",
    "    node = template_net.add_node(i)\n",
    "    node.set(\"Threshold\", 1)\n",
    "    template_net.add_output(i)\n",
    "\n",
    "proc.load_network(template_net)\n",
    "# track neuron updates\n",
    "for output_id in template_net.as_json()['Outputs']:\n",
    "    proc.track_neuron_events(output_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85b4733d-82aa-4328-b1bb-786fe18a6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging or other utilities \n",
    "def network_details(nw, log_json=False):\n",
    "    net_json = nw.as_json()\n",
    "\n",
    "    if log_json:\n",
    "        print(net_json)\n",
    "    \n",
    "    print(f'Network has {len(net_json[\"Edges\"])} synapses and {len(net_json[\"Nodes\"])} neurons')\n",
    "\n",
    "    # check if all out nodes have an incoming synapse\n",
    "    out_ids = net_json['Outputs']\n",
    "    for edge in net_json['Edges']:\n",
    "        if edge['to'] in out_ids:\n",
    "            out_ids.remove(edge['to'])\n",
    "\n",
    "    if len(out_ids) == 0:\n",
    "        print('All outputs have incoming connections')\n",
    "    else:\n",
    "        print(f'Outputs {out_ids} have no incoming connections')\n",
    "\n",
    "def compute_fitness(net):\n",
    "    proc.load_network(net)\n",
    "    #network_details(net)\n",
    "\n",
    "    correct = 0\n",
    "    for i in range(len(spikes)):\n",
    "        proc.clear_activity()\n",
    "\n",
    "        for c in spikes[i]: # spikes[i] is a single training sample\n",
    "            proc.apply_spikes(c)\n",
    "\n",
    "        proc.run(1000)\n",
    "\n",
    "        out_counts = proc.output_counts()\n",
    "\n",
    "        prediction = 0 if out_counts[0] > out_counts[1] else 1\n",
    "\n",
    "        if prediction == labels[i]:\n",
    "            correct += 1\n",
    "\n",
    "    return correct\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d224b7a-29e9-4f23-9d5e-e7407aecb388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 50, 50, 49, 49, 50, 50, 49, 48, 50, 50, 47, 50, 50, 44, 50, 47, 50, 46, 49, 50, 50, 48, 50, 50, 50, 50, 26, 53, 50, 50, 50, 44, 51, 50, 50, 50, 51, 50, 44, 50, 50, 46, 50, 50, 50, 50, 48, 40, 50]\n",
      "53\n",
      "[53, 51, 51, 50, 50, 50, 50, 50, 33, 50, 50, 50, 49, 50, 50, 47, 50, 50, 50, 41, 50, 50, 49, 39, 50, 50, 50, 51, 50, 51, 50, 50, 50, 50, 50, 50, 56, 50, 51, 50, 50, 55, 50, 50, 50, 50, 51, 50, 50, 50]\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "EPOCH_COUNT = 100\n",
    "eons_inst.set_template_network(template_net)\n",
    "pop = eons_inst.generate_population(eons_param, MOA.random_integer())\n",
    "\n",
    "for i in range(EPOCH_COUNT):\n",
    "    fits = [compute_fitness(n.network) for n in pop.networks]\n",
    "\n",
    "    print(f'{fits}')\n",
    "    best_score = max(fits)\n",
    "    print(f'{best_score}')\n",
    "\n",
    "    pop = eons_inst.do_epoch(pop, fits, eons_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b2c340-79a1-41c0-9f54-518c9891edd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
