{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893dd921-1942-4e44-83ae-1dab1fe06d15",
   "metadata": {},
   "source": [
    "# Setup\n",
    "This notebook is basically a mix of make_dataset.py from ../snn with encoding using delta modulation and adding waveform data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdec943e-84a4-407f-a115-0f704cbb44b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joao/dev/neuromorphic/neurovenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import speech2spikes\n",
    "import torchaudio\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import pywt\n",
    "import noisereduce\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common import write_spikes_to_disk\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b823c3e3-b02f-4383-b17b-32261bc229dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables for encoding\n",
    "MODE = 'dwt' # spec, dwt\n",
    "DATASET_CAP = 120\n",
    "FILEPATH = './data/null-dwt-wpndm.npz' # for saving\n",
    "DM_THRESHOLD = 0.05\n",
    "\n",
    "DWT_LEVELS = 7\n",
    "DWT_TIMESTEPS = 500\n",
    "\n",
    "SPEC_FREQ_BIN_COUNT = 25 # for spec mode\n",
    "\n",
    "PATH_GUNSHOT_SOUNDS = '/home/joao/dev/MLAudio/shotspotter/data/gunshots' \n",
    "PATH_GUNSHOT_INDEX = '/home/joao/dev/MLAudio/shotspotter/data/gunshotsNewIndex.csv'\n",
    "PATH_NOGUNSHOT_SOUNDS = '/home/joao/dev/MLAudio/shotspotter/data/genBackgrounds'\n",
    "\n",
    "### IMPORTANT: fix the part where we downsample the waveform, maybe use library to do it.\n",
    "### - only works now because coincidentally the bin size perfectly divides the sample count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c17a0ca-5d74-4c81-9f86-df2c8f65b4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 60 gunshot audio files\n",
      "We have 60 background only audio files\n"
     ]
    }
   ],
   "source": [
    "gunshot_file_paths = [PATH_GUNSHOT_SOUNDS+'/'+fn for fn in os.listdir(PATH_GUNSHOT_SOUNDS)][:DATASET_CAP//2]\n",
    "print(f'We have {len(gunshot_file_paths)} gunshot audio files')\n",
    "nogunshot_file_paths = [PATH_NOGUNSHOT_SOUNDS+'/'+fn for fn in os.listdir(PATH_NOGUNSHOT_SOUNDS)][:DATASET_CAP//2]\n",
    "print(f'We have {len(nogunshot_file_paths)} background only audio files')\n",
    "\n",
    "p1 = [(i, 1) for i in gunshot_file_paths]\n",
    "p2 = [(i, 0) for i in nogunshot_file_paths]\n",
    "\n",
    "pairs = p1+p2 # path to sound - label tuples\n",
    "random.shuffle(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c3ca59-566a-410a-850f-22f2766141ea",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ced40e-12b6-40dc-ac71-470a8f596563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input is shape time x batch x channels (from spectrogram or dwt spec)\n",
    "def posneg_delta(raw_spec_data):\n",
    "    delta = spikegen.delta(raw_spec_data, threshold=DM_THRESHOLD, off_spike=True)\n",
    "    \n",
    "    new_data = torch.zeros(delta.shape[0], delta.shape[1], delta.shape[2]*2, device=delta.device)\n",
    "\n",
    "    pos_mask = (delta == 1)\n",
    "    neg_mask = (delta == -1)\n",
    "\n",
    "    new_data[:, :, :delta.shape[2]] = pos_mask.to(torch.float32)\n",
    "    new_data[:, :, delta.shape[2]:] = neg_mask.to(torch.float32)\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def to_spikes(paths_list, labels):\n",
    "    if MODE == 'spec':\n",
    "        all_spikes = []\n",
    "        all_waveforms = []\n",
    "        targets = np.array(labels)\n",
    "\n",
    "        p_count = 0\n",
    "        for p in paths_list:\n",
    "            # log\n",
    "            p_count += 1\n",
    "            if p_count % 100 == 0:\n",
    "                print(f'Done {p_count} samples.')\n",
    "            \n",
    "            samples, rate = torchaudio.load(p, normalize=True)\n",
    "            \n",
    "            if samples.shape[0] == 2: samples = samples[0, :]\n",
    "            else: samples = samples[0]\n",
    "            if(len(samples) < 24000):\n",
    "                samples = torch.cat((samples, torch.tensor([0])))\n",
    "\n",
    "            #plt.plot(np.linspace(0, len(samples), len(samples)), samples)\n",
    "            \n",
    "            samples = torch.tensor(noisereduce.reduce_noise(y=samples, sr=rate)) # testing this because I had it on in the ResNet version dataset\n",
    "\n",
    "            #plt.plot(np.linspace(0, len(samples), len(samples)), samples)\n",
    "\n",
    "            # freq bin count is nfft//2 + 1\n",
    "            spec_transform = torchaudio.transforms.Spectrogram(n_fft=(2*SPEC_FREQ_BIN_COUNT-2))\n",
    "\n",
    "            samples = samples.to(torch.float64)\n",
    "            spec = spec_transform(samples)\n",
    "\n",
    "            # convert waveform to spikes\n",
    "            timesteps = spec.shape[1]\n",
    "            waveform_timestep_len = (24000//timesteps) + 1\n",
    "\n",
    "            ts_waveform = [] # timesteps but compressed to time resolution of spectrogram output\n",
    "            current_t = waveform_timestep_len\n",
    "            while current_t <= 24000:\n",
    "                ts_waveform.append(samples[current_t-waveform_timestep_len: current_t].max())\n",
    "                current_t += waveform_timestep_len\n",
    "\n",
    "            if len(ts_waveform) < timesteps: # pad so dimensions match\n",
    "                ts_waveform.append(0) \n",
    "\n",
    "            # normalize because amplitude scales vary a lot (and we did this in resnet accidentally)\n",
    "            ts_waveform = torch.tensor(ts_waveform)\n",
    "            ts_waveform = (ts_waveform - ts_waveform.min()) / (ts_waveform.max() - ts_waveform.min())\n",
    "\n",
    "            # debug\n",
    "            #plt.plot(np.linspace(0, len(samples), len(samples)), samples)\n",
    "            #plt.plot(np.linspace(0, len(ts_waveform), len(ts_waveform)), ts_waveform)\n",
    "\n",
    "            # convert compressed waveform into spikes using bins\n",
    "            waveform_spikes = []\n",
    "            num_bins = 20\n",
    "            bin_size = 1/num_bins\n",
    "            for w in ts_waveform:\n",
    "                waveform_spikes.append([0 for i in range(num_bins)])\n",
    "                waveform_spikes[-1][int(w//bin_size)] = 1\n",
    "\n",
    "            waveform_spikes = torch.tensor(waveform_spikes)\n",
    "\n",
    "            # debug\n",
    "            # fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "            # ax = fig.add_subplot(111)\n",
    "            # splt.raster(waveform_spikes, ax, s=5, c=\"black\")\n",
    "\n",
    "            all_spikes.append(spec)\n",
    "            all_waveforms.append(waveform_spikes)\n",
    "\n",
    "        # global max/min normalization\n",
    "        print('Looking for global max/min...')\n",
    "        global_min = 0\n",
    "        global_max = 0\n",
    "        for s in all_spikes:\n",
    "            if s.min() < global_min: global_min = s.min()\n",
    "            if s.max() > global_max: global_max = s.max()\n",
    "\n",
    "        # now normalize everything\n",
    "        print('Normalizing...')\n",
    "        for i in range(len(all_spikes)):\n",
    "            all_spikes[i] = (all_spikes[i]-global_min) / (global_max - global_min)\n",
    "\n",
    "        all_spikes = torch.stack(all_spikes)\n",
    "        all_waveforms = torch.stack(all_waveforms)\n",
    "\n",
    "        # delta modulate spectrogram\n",
    "        all_spikes = all_spikes.permute(2, 0, 1)\n",
    "        print('Running deltamod')\n",
    "        all_spikes_dm = posneg_delta(all_spikes)\n",
    "\n",
    "        # note: here, all_spikes_dm is (timestep, batch, neuron) and all_waveforms is (batch, timestep, neuron)\n",
    "        all_waveforms = all_waveforms.permute(1, 0, 2)\n",
    "\n",
    "        return torch.cat((all_spikes_dm, all_waveforms), dim=2), torch.tensor(labels)\n",
    "\n",
    "    # DWT MODE\n",
    "    elif MODE == 'dwt':\n",
    "        all_spikes = []\n",
    "        all_waveforms = []\n",
    "        targets = np.array(labels)\n",
    "\n",
    "        p_count = 0\n",
    "        for p in paths_list:\n",
    "            # log\n",
    "            p_count += 1\n",
    "            if p_count % 100 == 0:\n",
    "                print(f'Done {p_count} samples.')\n",
    "            \n",
    "            samples, rate = torchaudio.load(p, normalize=True)\n",
    "            \n",
    "            if samples.shape[0] == 2: samples = samples[0, :]\n",
    "            else: samples = samples[0]\n",
    "            if(len(samples) < 24000):\n",
    "                samples = torch.cat((samples, torch.tensor([0])))\n",
    "\n",
    "            #plt.plot(np.linspace(0, len(samples), len(samples)), samples)\n",
    "            \n",
    "            samples = torch.tensor(noisereduce.reduce_noise(y=samples, sr=rate)) # testing this because I had it on in the ResNet version dataset\n",
    "\n",
    "            #plt.plot(np.linspace(0, len(samples), len(samples)), samples)\n",
    "\n",
    "            coeffs = pywt.wavedec(samples, 'db1', level=DWT_LEVELS)\n",
    "\n",
    "            accum = np.abs(np.array([coeffs[-1]]))\n",
    "            for i in range(DWT_LEVELS - 1):\n",
    "                current_coef = coeffs[DWT_LEVELS - 1 - i]\n",
    "                r = np.abs(np.array([np.repeat(current_coef, pow(2, i + 1))]))\n",
    "                r = r[:, 0:rate]\n",
    "                accum = np.concatenate([accum, r])\n",
    "            \n",
    "            timestep_skip = rate//DWT_TIMESTEPS\n",
    "\n",
    "            channels = [[] for i in range(DWT_LEVELS)]\n",
    "            for i in range(rate//timestep_skip):\n",
    "                for j in range(DWT_LEVELS):\n",
    "                    channels[j].append(accum[j][i*timestep_skip])\n",
    "\n",
    "            channels = torch.tensor(channels)\n",
    "            channels = (channels - channels.min()) / (channels.max()-channels.min())\n",
    "\n",
    "            # convert waveform to spikes\n",
    "            timesteps = channels.shape[1]\n",
    "            waveform_timestep_len = (24000//timesteps)\n",
    "\n",
    "            ts_waveform = [] # timesteps but compressed to time resolution of spectrogram output\n",
    "            current_t = waveform_timestep_len\n",
    "            while current_t <= 24000:\n",
    "                ts_waveform.append(samples[current_t-waveform_timestep_len: current_t].max())\n",
    "                current_t += waveform_timestep_len\n",
    "\n",
    "            if len(ts_waveform) < timesteps: # pad so dimensions match\n",
    "                ts_waveform.append(0) \n",
    "\n",
    "            # normalize because amplitude scales vary a lot (and we did this in resnet)\n",
    "            ts_waveform = torch.tensor(ts_waveform)\n",
    "            ts_waveform = (ts_waveform - ts_waveform.min()) / (ts_waveform.max() - ts_waveform.min())\n",
    "\n",
    "            # debug\n",
    "            #plt.plot(np.linspace(0, len(samples), len(samples)), samples)\n",
    "            #plt.plot(np.linspace(0, len(ts_waveform), len(ts_waveform)), ts_waveform)\n",
    "\n",
    "            # convert compressed waveform into spikes using bins\n",
    "            waveform_spikes = []\n",
    "            num_bins = 20\n",
    "            bin_size = 1/num_bins\n",
    "            for w in ts_waveform:\n",
    "                waveform_spikes.append([0 for i in range(num_bins)])\n",
    "                waveform_spikes[-1][int(w//bin_size)] = 1\n",
    "\n",
    "            waveform_spikes = torch.tensor(waveform_spikes)\n",
    "\n",
    "            # debug\n",
    "            # fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "            # ax = fig.add_subplot(111)\n",
    "            # splt.raster(waveform_spikes, ax, s=5, c=\"black\")\n",
    "\n",
    "            all_spikes.append(channels)\n",
    "            all_waveforms.append(waveform_spikes)\n",
    "\n",
    "        # # global max/min normalization\n",
    "        # print('Looking for global max/min...')\n",
    "        # global_min = 0\n",
    "        # global_max = 0\n",
    "        # for s in all_spikes:\n",
    "        #     if s.min() < global_min: global_min = s.min()\n",
    "        #     if s.max() > global_max: global_max = s.max()\n",
    "\n",
    "        # # now normalize everything\n",
    "        # print('Normalizing...')\n",
    "        # for i in range(len(all_spikes)):\n",
    "        #     all_spikes[i] = (all_spikes[i]-global_min) / (global_max - global_min)\n",
    "\n",
    "        all_spikes = torch.stack(all_spikes)\n",
    "        all_waveforms = torch.stack(all_waveforms)\n",
    "\n",
    "        # delta modulate spectrogram\n",
    "        all_spikes = all_spikes.permute(2, 0, 1)\n",
    "        print('Running deltamod')\n",
    "        all_spikes_dm = posneg_delta(all_spikes)\n",
    "\n",
    "        # note: here, all_spikes_dm is (timestep, batch, neuron) and all_waveforms is (batch, timestep, neuron)\n",
    "        all_waveforms = all_waveforms.permute(1, 0, 2)\n",
    "\n",
    "        return torch.cat((all_spikes_dm, all_waveforms), dim=2), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20835810-da53-4388-b038-5accdd655f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 100 samples.\n",
      "Running deltamod\n"
     ]
    }
   ],
   "source": [
    "spikes, labels = to_spikes([i[0] for i in pairs], [i[1] for i in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09748309-0836-4d0f-b153-8b3b78564e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/validation/test split and save\n",
    "train_cutoff_index = int(DATASET_CAP*0.8)\n",
    "test_val_cutoff_offset = int(DATASET_CAP*0.1)\n",
    "training_spikes = spikes[:, 0:train_cutoff_index, :]\n",
    "training_labels = labels[0:train_cutoff_index]\n",
    "training_gunshot_data = []\n",
    "\n",
    "validation_spikes = spikes[:, train_cutoff_index:train_cutoff_index+test_val_cutoff_offset, :]\n",
    "validation_labels = labels[train_cutoff_index:train_cutoff_index+test_val_cutoff_offset]\n",
    "validation_gunshot_data = []\n",
    "validation_filenames = [i[0] for i in pairs][train_cutoff_index:train_cutoff_index+test_val_cutoff_offset]\n",
    "\n",
    "test_spikes = spikes[:, train_cutoff_index+test_val_cutoff_offset:, :]\n",
    "test_labels = labels[train_cutoff_index+test_val_cutoff_offset:]\n",
    "\n",
    "# metadata = [f'dm-threshold: {DM_THRESHOLD}', 'mode: dwt', 'format: snntorch', 'other: per sample norm just like resnet, max pool waveform']\n",
    "# write_spikes_to_disk(FILEPATH, metadata, training_spikes, training_labels, training_gunshot_data,\n",
    "# validation_spikes, validation_labels, validation_gunshot_data, validation_filenames, test_spikes, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8eafd0a1-a75d-412b-9b5b-27efaceff5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize output\n",
    "INDEX = 3\n",
    "\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "splt.raster(spikes[:, INDEX, :], ax, s=1, c=\"black\")\n",
    "print(labels[INDEX])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbd3af8-8ffb-4cf7-804f-181b80575fa7",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69195a2-7325-4b95-b0bf-d40537e55381",
   "metadata": {},
   "source": [
    "# Convolution Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5261eb69-b7d5-4977-85a7-0f60c2693036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 34])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spk = spikes[:, 3, :]\n",
    "\n",
    "WINDOW_SIZE = 50\n",
    "HOP_LENGTH = 25\n",
    "TIMESTEPS = spk.shape[0]\n",
    "\n",
    "spk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccf46c-ee8d-47cf-a79f-840c1925fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for i in range(TIMESTEPS//HOP_LENGTH):\n",
    "    print(i*HOP_LENGTH, i*HOP_LENGTH+WINDOW_SIZE)\n",
    "    frames.append(spk[i*HOP_LENGTH:i*HOP_LENGTH+WINDOW_SIZE, :])\n",
    "\n",
    "    # if we need to pad\n",
    "    if i*HOP_LENGTH+WINDOW_SIZE > TIMESTEPS:\n",
    "        print('padding...')\n",
    "        pad = torch.zeros(i*HOP_LENGTH+WINDOW_SIZE - TIMESTEPS, spk.shape[1])\n",
    "        frames[-1] = torch.cat((frames[-1], pad), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98d271-c23c-4ec8-9710-58914a7c7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in frames:\n",
    "    fig = plt.figure(facecolor=\"w\", figsize=(3, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    splt.raster(f, ax, s=1, c=\"black\")\n",
    "    plt.ylim(0, 35)\n",
    "    plt.xlim(0, WINDOW_SIZE) # to properly show padding\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3f67a-2545-435d-a8b6-de828f413ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
